{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcf8ab5-b322-4989-99f8-9da3ee245fcc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a518cb5-53ba-4d52-b58a-2829a44a83ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import nest as sim\n",
    "import numpy as np\n",
    "import pandas\n",
    "from collections import Counter\n",
    "import time as tm\n",
    "import scipy.stats\n",
    "import scipy.io\n",
    "from time import sleep, process_time\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c94a964-a8b1-43c4-a14f-e7697c2f80b2",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff57a181-d5c9-4bc2-921f-b630d972e52b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cart2ring(x, y, offset):\n",
    "\n",
    "    if not isinstance(x, np.ndarray):\n",
    "\n",
    "        x = np.array(x)\n",
    "\n",
    "    if not isinstance(y, np.ndarray):\n",
    "\n",
    "        y = np.array(y)\n",
    "\n",
    "    assert x.size == y.size\n",
    "    assert x.size > 0\n",
    "\n",
    "    if x.size == 1:\n",
    "\n",
    "        projection_r1 = np.dot(np.array([x, y]), np.array([x, -x / np.tan(np.radians(offset))])) / np.linalg.norm(np.array([x, -x / np.tan(np.radians(offset))]))\n",
    "        projection_r2 = np.dot(np.array([x, y]), np.array([x, -x / np.tan(np.radians(60 + offset))])) / np.linalg.norm(np.array([x, -x / np.tan(np.radians(60 + offset))]))\n",
    "        projection_r3 = np.dot(np.array([x, y]), np.array([x, x / np.tan(np.radians(60 - offset))])) / np.linalg.norm(np.array([x, x / np.tan(np.radians(60 - offset))]))\n",
    "\n",
    "    elif x.size > 1:\n",
    "\n",
    "        projection_r1 = np.array([np.dot(np.array([i, j]), np.array([i, -i / np.tan(np.radians(offset))])) / np.linalg.norm(np.array([i, -i / np.tan(np.radians(offset))])) for i, j in zip(x, y)])\n",
    "        projection_r2 = np.array([np.dot(np.array([i, j]), np.array([i, -i / np.tan(np.radians(60 + offset))])) / np.linalg.norm(np.array([i, -i / np.tan(np.radians(60 + offset))])) for i, j in zip(x, y)])\n",
    "        projection_r3 = np.array([np.dot(np.array([i, j]), np.array([i, i / np.tan(np.radians(60 - offset))])) / np.linalg.norm(np.array([i, i / np.tan(np.radians(60 - offset))])) for i, j in zip(x, y)])\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "    offset = offset % 360\n",
    "\n",
    "    if offset >= 0 and offset < 60:\n",
    "\n",
    "        ring1 = -np.sign(x) * projection_r1\n",
    "        ring2 = -np.sign(x) * projection_r2\n",
    "        ring3 = -np.sign(x) * projection_r3\n",
    "\n",
    "    elif offset >= 60 and offset < 120:\n",
    "\n",
    "        ring1 = -np.sign(x) * projection_r1\n",
    "        ring2 = -np.sign(x) * projection_r2\n",
    "        ring3 = np.sign(x) * projection_r3\n",
    "\n",
    "    elif offset >= 120 and offset < 180:\n",
    "\n",
    "        ring1 = -np.sign(x) * projection_r1\n",
    "        ring2 = np.sign(x) * projection_r2\n",
    "        ring3 = np.sign(x) * projection_r3\n",
    "\n",
    "    elif offset >= 180 and offset < 240:\n",
    "\n",
    "        ring1 = np.sign(x) * projection_r1\n",
    "        ring2 = np.sign(x) * projection_r2\n",
    "        ring3 = np.sign(x) * projection_r3\n",
    "\n",
    "    elif offset >= 240 and offset < 300:\n",
    "\n",
    "        ring1 = np.sign(x) * projection_r1\n",
    "        ring2 = np.sign(x) * projection_r2\n",
    "        ring3 = -np.sign(x) * projection_r3\n",
    "\n",
    "    elif offset >= 300 and offset < 360:\n",
    "\n",
    "        ring1 = np.sign(x) * projection_r1\n",
    "        ring2 = -np.sign(x) * projection_r2\n",
    "        ring3 = -np.sign(x) * projection_r3\n",
    "\n",
    "    return np.array([ring1, ring2, ring3]).T\n",
    "\n",
    "def ring2cart(ring1, ring2, ring3, offset):\n",
    "\n",
    "    if not isinstance(ring1, np.ndarray):\n",
    "\n",
    "        ring1 = np.array(ring1)\n",
    "\n",
    "    if not isinstance(ring2, np.ndarray):\n",
    "\n",
    "        ring2 = np.array(ring2)\n",
    "\n",
    "    if not isinstance(ring3, np.ndarray):\n",
    "\n",
    "        ring3 = np.array(ring3)\n",
    "\n",
    "    assert ring1.size > 0    \n",
    "\n",
    "    danger_values_r1 = [x for x in range(0, 360, 90)] # r1 will align with x or y at these offset values\n",
    "    danger_values_r2 = [x for x in range(30, 360, 90)] # r2 will align with x or y at these offset values\n",
    "    danger_values_r3 = [x for x in range(60, 360, 90)] # r3 will align with x or y at these offset values\n",
    "\n",
    "    ### New method: Use intersection of normals to find the corresponding (x,y) \n",
    "\n",
    "    # Draw ring axes that span the length of the arena in question\n",
    "    # The maximum extent of x and y are equal to the longest ring\n",
    "    # The largest ratio of ring:cartesian values are if a ring axis is aligned exactly to x or y\n",
    "    # Therefore, no point in ring space can be outside the corresponding bounds in cartesian space\n",
    "\n",
    "    offset = offset % 360\n",
    "\n",
    "    if offset not in danger_values_r1 and offset not in danger_values_r2 and offset not in danger_values_r3:\n",
    "\n",
    "        max_x = np.max([ring1, ring2, ring3], axis = 0) / np.cos(np.radians(np.max([offset, offset + 60, offset + 120])))\n",
    "        min_x = -max_x\n",
    "\n",
    "        ring1_y = ring1 / np.cos(np.radians(offset))\n",
    "        ring2_y = ring2 / np.cos(np.radians(60 + offset))\n",
    "        ring3_y = -ring3 / np.cos(np.radians(60 - offset))\n",
    "\n",
    "        y_r1_n_start    =  -max_x * np.tan(np.radians(offset)) + ring1_y\n",
    "        y_r1_n_end      =  -min_x * np.tan(np.radians(offset)) + ring1_y\n",
    "\n",
    "        y_r2_n_start    =  -max_x * np.tan(np.radians(60 + offset)) + ring2_y\n",
    "        y_r2_n_end      =  -min_x * np.tan(np.radians(60 + offset)) + ring2_y\n",
    "\n",
    "        y_r3_n_start    =  max_x * np.tan(np.radians(60 - offset)) + ring3_y\n",
    "        y_r3_n_end      =  min_x * np.tan(np.radians(60 - offset)) + ring3_y\n",
    "\n",
    "        # Get start and end points of ring axes\n",
    "\n",
    "        start_r1_n = np.array([min_x, y_r1_n_start])\n",
    "        start_r2_n = np.array([min_x, y_r2_n_start])\n",
    "        start_r3_n = np.array([min_x, y_r3_n_start])\n",
    "\n",
    "        end_r1_n = np.array([max_x, y_r1_n_end])\n",
    "        end_r2_n = np.array([max_x, y_r2_n_end])\n",
    "        end_r3_n = np.array([max_x, y_r3_n_end])\n",
    "\n",
    "        x_values = np.empty(shape = (ring1.size, 3))\n",
    "        y_values = np.empty(shape = (ring1.size, 3))\n",
    "\n",
    "        # Calculate where each pair intersects\n",
    "\n",
    "        x1,y1 = start_r1_n\n",
    "        x2,y2 = end_r1_n\n",
    "        x3,y3 = start_r2_n\n",
    "        x4,y4 = end_r2_n\n",
    "\n",
    "        denom = (y4-y3)*(x2-x1) - (x4-x3)*(y2-y1)\n",
    "\n",
    "        denom[(denom < 0.001) & (denom >= 0)] = 0.001\n",
    "        denom[(denom > -0.001) & (denom < 0)] = -0.001\n",
    "\n",
    "        ua = ((x4-x3)*(y1-y3) - (y4-y3)*(x1-x3)) / denom\n",
    "        ub = ((x2-x1)*(y1-y3) - (y2-y1)*(x1-x3)) / denom\n",
    "        x = x3 + ua * (x4-x3)\n",
    "        y = y3 + ua * (y4-y3)\n",
    "\n",
    "        x_values[:, 0] = x\n",
    "        y_values[:, 0] = y\n",
    "\n",
    "        x1,y1 = start_r2_n\n",
    "        x2,y2 = end_r2_n\n",
    "        x3,y3 = start_r3_n\n",
    "        x4,y4 = end_r3_n\n",
    "\n",
    "        denom = (y4-y3)*(x2-x1) - (x4-x3)*(y2-y1)\n",
    "\n",
    "        denom[(denom < 0.001) & (denom >= 0)] = 0.001\n",
    "        denom[(denom > -0.001) & (denom < 0)] = -0.001\n",
    "\n",
    "        ua = ((x4-x3)*(y1-y3) - (y4-y3)*(x1-x3)) / denom\n",
    "        ub = ((x2-x1)*(y1-y3) - (y2-y1)*(x1-x3)) / denom\n",
    "        x = x3 + ua * (x4-x3)\n",
    "        y = y3 + ua * (y4-y3)\n",
    "\n",
    "        x_values[:, 1] = x\n",
    "        y_values[:, 1] = y\n",
    "\n",
    "        x1,y1 = start_r1_n\n",
    "        x2,y2 = end_r1_n\n",
    "        x3,y3 = start_r3_n\n",
    "        x4,y4 = end_r3_n\n",
    "\n",
    "        denom = (y4-y3)*(x2-x1) - (x4-x3)*(y2-y1)\n",
    "\n",
    "        denom[(denom < 0.001) & (denom >= 0)] = 0.001\n",
    "        denom[(denom > -0.001) & (denom < 0)] = -0.001\n",
    "\n",
    "        ua = ((x4-x3)*(y1-y3) - (y4-y3)*(x1-x3)) / denom\n",
    "        ub = ((x2-x1)*(y1-y3) - (y2-y1)*(x1-x3)) / denom\n",
    "        x = x3 + ua * (x4-x3)\n",
    "        y = y3 + ua * (y4-y3)\n",
    "\n",
    "        x_values[:, 2] = x\n",
    "        y_values[:, 2] = y\n",
    "\n",
    "    elif offset in danger_values_r1:\n",
    "\n",
    "        max_x = np.max([ring2, ring3], axis = 0) / np.cos(np.radians(np.max([offset, offset + 60, offset + 120])))\n",
    "        min_x = -max_x\n",
    "\n",
    "        ring2_y = ring2 / np.cos(np.radians(60 + offset))\n",
    "        ring3_y = -ring3 / np.cos(np.radians(60 - offset))\n",
    "\n",
    "        y_r2_n_start    =  -max_x * np.tan(np.radians(60 + offset)) + ring2_y\n",
    "        y_r2_n_end      =  -min_x * np.tan(np.radians(60 + offset)) + ring2_y\n",
    "\n",
    "        y_r3_n_start    =  max_x * np.tan(np.radians(60 - offset)) + ring3_y\n",
    "        y_r3_n_end      =  min_x * np.tan(np.radians(60 - offset)) + ring3_y\n",
    "\n",
    "        # Get start and end points of ring axes\n",
    "\n",
    "        start_r2_n = np.array([min_x, y_r2_n_start])\n",
    "        start_r3_n = np.array([min_x, y_r3_n_start])\n",
    "\n",
    "        end_r2_n = np.array([max_x, y_r2_n_end])\n",
    "        end_r3_n = np.array([max_x, y_r3_n_end])\n",
    "\n",
    "        x_values = np.empty(shape = (ring1.size, 1))\n",
    "        y_values = np.empty(shape = (ring1.size, 1))\n",
    "\n",
    "        # Calculate where each pair intersects\n",
    "\n",
    "        x1,y1 = start_r2_n\n",
    "        x2,y2 = end_r2_n\n",
    "        x3,y3 = start_r3_n\n",
    "        x4,y4 = end_r3_n\n",
    "\n",
    "        denom = (y4-y3)*(x2-x1) - (x4-x3)*(y2-y1)\n",
    "\n",
    "        denom[(denom < 0.001) & (denom >= 0)] = 0.001\n",
    "        denom[(denom > -0.001) & (denom < 0)] = -0.001\n",
    "\n",
    "        ua = ((x4-x3)*(y1-y3) - (y4-y3)*(x1-x3)) / denom\n",
    "        ub = ((x2-x1)*(y1-y3) - (y2-y1)*(x1-x3)) / denom\n",
    "        x = x3 + ua * (x4-x3)\n",
    "        y = y3 + ua * (y4-y3)\n",
    "\n",
    "        x_values[:, 0] = x\n",
    "        y_values[:, 0] = y\n",
    "\n",
    "    elif offset in danger_values_r2:\n",
    "\n",
    "        max_x = np.max([ring1, ring3], axis = 0) / np.cos(np.radians(np.max([offset, offset + 60, offset + 120])))\n",
    "        min_x = -max_x\n",
    "\n",
    "        ring1_y = ring1 / np.cos(np.radians(offset))\n",
    "        ring3_y = -ring3 / np.cos(np.radians(60 - offset))\n",
    "\n",
    "        y_r1_n_start    =  -max_x * np.tan(np.radians(offset)) + ring1_y\n",
    "        y_r1_n_end      =  -min_x * np.tan(np.radians(offset)) + ring1_y\n",
    "\n",
    "        y_r3_n_start    =  max_x * np.tan(np.radians(60 - offset)) + ring3_y\n",
    "        y_r3_n_end      =  min_x * np.tan(np.radians(60 - offset)) + ring3_y\n",
    "\n",
    "        # Get start and end points of ring axes\n",
    "\n",
    "        start_r1_n = np.array([min_x, y_r1_n_start])\n",
    "        start_r3_n = np.array([min_x, y_r3_n_start])\n",
    "\n",
    "        end_r1_n = np.array([max_x, y_r1_n_end])\n",
    "        end_r3_n = np.array([max_x, y_r3_n_end])\n",
    "\n",
    "        x_values = np.empty(shape = (ring1.size, 1))\n",
    "        y_values = np.empty(shape = (ring1.size, 1))\n",
    "\n",
    "        # Calculate where each pair intersects\n",
    "\n",
    "        x1,y1 = start_r1_n\n",
    "        x2,y2 = end_r1_n\n",
    "        x3,y3 = start_r3_n\n",
    "        x4,y4 = end_r3_n\n",
    "\n",
    "        denom = (y4-y3)*(x2-x1) - (x4-x3)*(y2-y1)\n",
    "\n",
    "        denom[(denom < 0.001) & (denom >= 0)] = 0.001\n",
    "        denom[(denom > -0.001) & (denom < 0)] = -0.001\n",
    "\n",
    "        ua = ((x4-x3)*(y1-y3) - (y4-y3)*(x1-x3)) / denom\n",
    "        ub = ((x2-x1)*(y1-y3) - (y2-y1)*(x1-x3)) / denom\n",
    "        x = x3 + ua * (x4-x3)\n",
    "        y = y3 + ua * (y4-y3)\n",
    "\n",
    "        x_values[:, 0] = x\n",
    "        y_values[:, 0] = y\n",
    "\n",
    "    elif offset in danger_values_r3:\n",
    "\n",
    "        max_x = np.max([ring2, ring3], axis = 0) / np.cos(np.radians(np.max([offset, offset + 60, offset + 120])))\n",
    "        min_x = -max_x\n",
    "\n",
    "        ring1_y = ring1 / np.cos(np.radians(offset))\n",
    "        ring2_y = ring2 / np.cos(np.radians(60 + offset))\n",
    "\n",
    "        y_r1_n_start    =  -max_x * np.tan(np.radians(offset)) + ring1_y\n",
    "        y_r1_n_end      =  -min_x * np.tan(np.radians(offset)) + ring1_y\n",
    "\n",
    "        y_r2_n_start    =  -max_x * np.tan(np.radians(60 + offset)) + ring2_y\n",
    "        y_r2_n_end      =  -min_x * np.tan(np.radians(60 + offset)) + ring2_y\n",
    "\n",
    "        # Get start and end points of ring axes\n",
    "\n",
    "        start_r1_n = np.array([min_x, y_r1_n_start])\n",
    "        start_r2_n = np.array([min_x, y_r2_n_start])\n",
    "\n",
    "        end_r1_n = np.array([max_x, y_r1_n_end])\n",
    "        end_r2_n = np.array([max_x, y_r2_n_end])\n",
    "\n",
    "        x_values = np.empty(shape = (ring1.size, 1))\n",
    "        y_values = np.empty(shape = (ring1.size, 1))\n",
    "\n",
    "        # Calculate where each pair intersects\n",
    "\n",
    "        x1,y1 = start_r1_n\n",
    "        x2,y2 = end_r1_n\n",
    "        x3,y3 = start_r2_n\n",
    "        x4,y4 = end_r2_n\n",
    "\n",
    "        denom = (y4-y3)*(x2-x1) - (x4-x3)*(y2-y1)\n",
    "\n",
    "        denom[(denom < 0.001) & (denom >= 0)] = 0.001\n",
    "        denom[(denom > -0.001) & (denom < 0)] = -0.001\n",
    "\n",
    "        ua = ((x4-x3)*(y1-y3) - (y4-y3)*(x1-x3)) / denom\n",
    "        ub = ((x2-x1)*(y1-y3) - (y2-y1)*(x1-x3)) / denom\n",
    "        x = x3 + ua * (x4-x3)\n",
    "        y = y3 + ua * (y4-y3)\n",
    "\n",
    "        x_values[:, 0] = x\n",
    "        y_values[:, 0] = y\n",
    "\n",
    "\n",
    "    x = np.squeeze(np.mean(x_values, axis = 1))\n",
    "    y = np.squeeze(np.mean(y_values, axis = 1))\n",
    "\n",
    "    return np.array([x, y]).T\n",
    "\n",
    "def wrap_to_distance(distance, boundary):\n",
    "\n",
    "    wrapped = distance.copy()\n",
    "\n",
    "    wrapped[distance > 0] = distance[distance > 0] % boundary\n",
    "    wrapped[distance < 0] = distance[distance < 0] % boundary\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "def ring_mean_activity(data, centre = True):\n",
    "\n",
    "    # Data is expected to be a single ring's activity history of shape (timesteps, ring_size)\n",
    "\n",
    "    # Centre == False: rays are from 0 -> 2pi, half-open interval. Centre == True: rays are adjusted to project from halfway along their arc\n",
    "\n",
    "    ring_size = data.shape[1]\n",
    "\n",
    "    arc_per_ring_segment = (2 * np.pi) / ring_size\n",
    "\n",
    "    rays = np.repeat(np.arange(0, 2 * np.pi, arc_per_ring_segment).reshape(1, -1), data.shape[0], axis = 0)\n",
    "\n",
    "    if centre:\n",
    "\n",
    "        rays = rays + arc_per_ring_segment / 2\n",
    "\n",
    "    rays_for_each_spike = np.empty(shape = (data.shape[0]), dtype = 'object')\n",
    "\n",
    "    mean_activity = np.empty(shape = (data.shape[0]), dtype = 'float')\n",
    "\n",
    "    #for i, ray, count in enumerate(zip(rays, ray_counts)):\n",
    "    for i in range(rays_for_each_spike.shape[0]):\n",
    "\n",
    "        if len(np.nonzero(data[i,:])) > 0:\n",
    "\n",
    "            rays_for_each_spike[i] = np.repeat(rays[i,:][np.nonzero(data[i,:])], data[i, :][np.nonzero(data[i,:])].astype('int'))\n",
    "\n",
    "            mean_activity[i] = np.arctan2(np.mean(np.sin(rays_for_each_spike[i])), np.mean(np.cos(rays_for_each_spike[i]))) % (2 * np.pi)\n",
    "\n",
    "        else:\n",
    "\n",
    "            mean_activity[i] = 0\n",
    "\n",
    "        mean_activity[np.isnan(mean_activity)] = 0\n",
    "\n",
    "    mean_activity_ring_index = mean_activity * (ring_size / (2*np.pi))\n",
    "\n",
    "    return mean_activity_ring_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4747ee9f-06c9-4568-8f29-8fac4ae51fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "\n",
    "    sim.set_verbosity(\"M_ERROR\")\n",
    "    \n",
    "    sim.ResetKernel()\n",
    "    \n",
    "    sim.local_num_threads = 8 # NEST recommends 1 thread per core\n",
    "\n",
    "    # 'simulate': Run on NEST to generate results, this will save the results to .npy files\n",
    "    # 'load': Load a prior run without running the NEST simulator\n",
    "\n",
    "    simulate_or_load = 'simulate'\n",
    "\n",
    "    # 'spiral': Generate a spiral trajectory\n",
    "    # 'rat': Load one or more Sargolini datasets from file\n",
    "\n",
    "    spiral_or_rat = 'rat'\n",
    "    concatenate_rat = False\n",
    "\n",
    "    np.setbufsize(8192 * 4)\n",
    "\n",
    "    # Population cell counts\n",
    "\n",
    "    # N_ex: number of cells in the excitatory rings\n",
    "    # N_in: number of cells in the inhibitory rings\n",
    "    # N_cj: number of cells in the conjunctive rings\n",
    "    # rings: number of mono-axis rings ('directional rings')\n",
    "    # omni_rings: number of axis-invariant rings ('speed rings')\n",
    "    # window_size: how large a window of excitatory ring cells is each principle axis cell sensitive to?\n",
    "    # N_pa_cells_per_ring: how many PA cells exist for each ring (more = finer binning of excitatory ring activity)\n",
    "    # N_pyramidals: how many pyramidal cells are there?\n",
    "\n",
    "    calibration_mode = False # Set input to 0, to study static ring\n",
    "    corrections = True\n",
    "\n",
    "    N_ex = 120\n",
    "    N_in = N_ex\n",
    "    N_cj = N_ex\n",
    "\n",
    "    rings = 3\n",
    "    omni_rings = 0\n",
    "\n",
    "    window_size = 15\n",
    "\n",
    "    N_pa_cells_per_ring = N_ex // window_size\n",
    "\n",
    "    rp_offset = 0\n",
    "\n",
    "    N_pyramidals = N_pa_cells_per_ring ** rings\n",
    "\n",
    "    tension = True\n",
    "\n",
    "    minimum_input = 2700#675#2000#1000\n",
    "\n",
    "    # Connection Gaussian weight parameters\n",
    "\n",
    "    # sigma: variance for excitatory ring -> inhibitory ring weight Gaussian\n",
    "    # in_sigma: variance for inhibitory ring -> excitatory ring weight Gaussian\n",
    "    # in_cj_sigma: variance for inhibitory ring -> conjunctive rings weight Gaussian\n",
    "    # mu: mean offset of Gaussians (when used)\n",
    "    # prune_smaller_than: weights below this threshold will become 0, effectively removing the connection\n",
    "\n",
    "    sigma = 0.1#0.12#0.1\n",
    "    in_sigma = 0.1\n",
    "    in_cj_sigma = 0.09375#0.075#0.095#0.0925#0.08#0.09#0.08 # was at about 1-1.02 before, when coming back to this, give these a try\n",
    "    mu = 0.5\n",
    "    prune_smaller_than = 10\n",
    "\n",
    "    smooth_sigma = 10\n",
    "\n",
    "    # Connection scalar weight parameters. These are signed as appropriate later on\n",
    "\n",
    "    # base_ex: excitatory ring -> inhibitory ring weight strength (+)\n",
    "    # base_in: inhibitory ring -> excitatory ring weight strength (-)\n",
    "    # base_cj: conjunctive rings -> excitatory rings weight strength (+)\n",
    "    # w_ex_cj: excitatory rings -> conjunctive rings weight strength (+)\n",
    "    # w_in_cj: inhibitory_rings -> conjunctive rings weight strength (-)\n",
    "    # w_ex_pa: excitatory_rings -> principle axis cells weight strength (+)\n",
    "    # w_pa_py: principle axis cells -> pyramidal cells weight strength (+)\n",
    "\n",
    "    # Spiral settings:\n",
    "\n",
    "    # base_ex = 5000\n",
    "    # base_in = 1500\n",
    "    # base_cj = 500\n",
    "    # w_ex_cj = 440\n",
    "    # w_in_cj = 1800 # Was about 800 before, put up a lot higher before velocity calculation was changed to properly share out input\n",
    "    # w_ex_pa = 300\n",
    "    # w_pa_py = 200\n",
    "\n",
    "    # Rat settings:\n",
    "\n",
    "    # Next week: dropping inhibition is helping with integrating small velocities, try to lower it further and lower excitation too if needs be\n",
    "\n",
    "    base_ex = 1750#4000#5000\n",
    "    base_in = 0#5000#1500\n",
    "    base_cj = 500\n",
    "    w_ex_cj = 0\n",
    "    w_in_cj = 3000#3500#4000#4500#3600#1700#700 # Was about 800 before, put up a lot higher before velocity calculation was changed to properly share out input\n",
    "    w_ex_pa = 100#80\n",
    "    w_pa_py = 300\n",
    "    w_in_pa = 1000\n",
    "\n",
    "    cj_in_offset = 0 # Is the inhibitory 'bowl' biased towards the direction of input? If so, by how many cells?\n",
    "\n",
    "    # Synaptic transmission delay (I believe this includes the synapse proper and action potential travel time)\n",
    "\n",
    "    delay = 0.1\n",
    "\n",
    "    # Velocity scaling parameters\n",
    "\n",
    "    # I_vel: multiply incoming velocity by this amount to get the input current representing the vestibular signal\n",
    "    # velocity_threshold: Are very small values for velocity set to zero?\n",
    "    # miniumum_velocity: What is the minimum non-zero velocity? (only works if velocity_threshold is True)\n",
    "\n",
    "    I_vel = 2000000#800 # Seems to work best if you can get the velocities in a 0-4000 range\n",
    "\n",
    "    # Are conjuctive cells synapsed onto by excitatory layer or inhibitory layer.\n",
    "\n",
    "    # 'positive': scalar excitatory weight, conjunctive weights must be tuned to act as a coincidence detector for input velocity and bump activity\n",
    "    # 'negative': Gaussian inhibitory weight, suppresses incoming velocity input too far from the attractor bump\n",
    "    # 'both': inhibitory 'bowl' as per 'negative' and self-reinforcing excitatory connections\n",
    "\n",
    "    conjunctive_mode = 'negative'\n",
    "\n",
    "    # Intrinsic excitation of the excitatory ring, constant current in picoamps\n",
    "\n",
    "    intrinsic_excitation = 0.#225.\n",
    "\n",
    "    theta = False\n",
    "    \n",
    "    stochastic_membrane_potential = True\n",
    "    \n",
    "    stochastic_input_current = True\n",
    "\n",
    "    # Initial (bump-forming) current injection parameters. This is a short spike of input to form the initial attractor state, to be adjusted by conjunctive input\n",
    "\n",
    "    # I_init: strength of input current in picoamps\n",
    "    # I_init_dur: how long this is applied for, in milliseconds\n",
    "    # I_init_pos: where is this applied, in ring index (1-120). NEST, for better or worse, has neuron IDs starting at 1\n",
    "\n",
    "    I_init = 350.0#300.0\n",
    "    I_init_dur = 100.0\n",
    "    I_init_pos = 60 - 1#(N_ex - 1)\n",
    "    \n",
    "    N_vp = sim.GetKernelStatus(['total_num_virtual_procs'])[0]\n",
    "\n",
    "    if not os.path.exists(\"results_window_size_15.csv\"):\n",
    "\n",
    "        master_seed = 9032867582\n",
    "\n",
    "        N_vp = sim.GetKernelStatus(['total_num_virtual_procs'])[0]\n",
    "\n",
    "        sim.SetKernelStatus({'grng_seed' : master_seed+N_vp})\n",
    "\n",
    "        sim.SetKernelStatus({'rng_seeds' : range(master_seed+N_vp+1, master_seed+2*N_vp+1)})\n",
    "\n",
    "        membrane_seed = 2390786556\n",
    "\n",
    "        input_seed = 6983476394\n",
    "\n",
    "    else:\n",
    "\n",
    "        results_dataframe = pd.read_csv(\"results_window_size_15.csv\")\n",
    "\n",
    "        master_seed = results_dataframe[\"Master Seed\"].to_numpy()[-1] + 1\n",
    "\n",
    "        sim.SetKernelStatus({'grng_seed' : master_seed+N_vp})\n",
    "\n",
    "        sim.SetKernelStatus({'rng_seeds' : range(master_seed+N_vp+1, master_seed+2*N_vp+1)})\n",
    "\n",
    "        membrane_seed = results_dataframe[\"Membrane Seed\"].to_numpy()[-1] + 1\n",
    "\n",
    "        input_seed = results_dataframe[\"Input Seed\"].to_numpy()[-1] + 1\n",
    "        \n",
    "    membrane_rng = np.random.default_rng(seed = membrane_seed)\n",
    "    \n",
    "    input_rng = np.random.default_rng(seed = input_seed)\n",
    "\n",
    "    ## Create neuron populations from the above parameters\n",
    "\n",
    "    # Lists to store each ring's population\n",
    "\n",
    "    exc = []\n",
    "    inh = []\n",
    "    l = []\n",
    "    r = []\n",
    "    pa_cells = []\n",
    "    #input_pa_cells = []\n",
    "\n",
    "    for i in range(rings):\n",
    "\n",
    "        exc.append(sim.Create(\"iaf_psc_alpha\", N_ex))\n",
    "\n",
    "        inh.append(sim.Create(\"iaf_psc_alpha\", N_in)) # Inhibitory layer\n",
    "\n",
    "        l.append(sim.Create(\"iaf_psc_alpha\", N_cj)) # Conjunctive layer for left turn\n",
    "        r.append(sim.Create(\"iaf_psc_alpha\", N_cj)) # Conjunctive layer for right turn\n",
    "\n",
    "        pa_cells.append(sim.Create(\"iaf_psc_alpha\", N_pa_cells_per_ring))\n",
    "\n",
    "        #input_pa_cells.append(sim.Create(\"iaf_psc_alpha\",N_pa_cells_per_ring))\n",
    "\n",
    "    # The pyramidal cells associate across rings    \n",
    "\n",
    "    pyramidal_cells = sim.Create(\"iaf_psc_alpha\", N_pyramidals)\n",
    "    \n",
    "    if stochastic_membrane_potential:\n",
    "        \n",
    "        for ring in range(rings):\n",
    "            \n",
    "            for neuron in exc[ring]:\n",
    "                \n",
    "                sim.SetStatus([neuron], params = {\"V_m\": membrane_rng.integers(low = -70, high = 55) * 1.})\n",
    "                \n",
    "            for neuron in inh[ring]:\n",
    "                \n",
    "                sim.SetStatus([neuron], params = {\"V_m\": membrane_rng.integers(low = -70, high = 55) * 1.})\n",
    "                \n",
    "            for neuron in l[ring]:\n",
    "                \n",
    "                sim.SetStatus([neuron], params = {\"V_m\": membrane_rng.integers(low = -70, high = 55) * 1.})\n",
    "                \n",
    "            for neuron in r[ring]:\n",
    "                \n",
    "                sim.SetStatus([neuron], params = {\"V_m\": membrane_rng.integers(low = -70, high = 55) * 1.})\n",
    "                              \n",
    "            for neuron in pa_cells[ring]:\n",
    "                \n",
    "                sim.SetStatus([neuron], params = {\"V_m\": membrane_rng.integers(low = -70, high = 55) * 1.})\n",
    "                \n",
    "        for neuron in pyramidal_cells:\n",
    "\n",
    "            sim.SetStatus([neuron], params = {\"V_m\": membrane_rng.integers(low = -70, high = 55) * 1.})\n",
    "\n",
    "                \n",
    "    input_grid_devices = sim.Create('step_current_generator', N_pyramidals)\n",
    "\n",
    "    ## Define connection weight matrices\n",
    "\n",
    "    # Empty matrices\n",
    "\n",
    "    w_ex = np.empty((N_in,N_ex))\n",
    "    w_in = np.empty((N_ex,N_in))\n",
    "\n",
    "    for e in range(N_ex):\n",
    "        for i in range(N_in):\n",
    "            # Find minimum (true) distance between adjacent cells\n",
    "            d1 = abs(e/N_ex - i/N_in)\n",
    "            d2 = abs(e/N_ex - i/N_in -1)\n",
    "            d3 = abs(e/N_ex - i/N_in +1)\n",
    "            d = min(abs(d1),abs(d2),abs(d3))\n",
    "            # Create gaussian value based on parameters above to define connection strengths\n",
    "            w_gauss = np.exp(-(d - mu)**2/2/sigma**2) # Exitatory -> inhibitory\n",
    "            w_ring = np.exp(-(d)**2/2/in_sigma**2) # Inhibitory -> excitatory\n",
    "            # Assign appropriate weight values to matrices\n",
    "            w_ex[i,e] = base_ex * w_gauss\n",
    "            w_in[e,i] = base_in * w_ring \n",
    "\n",
    "    # Very small weights become 0\n",
    "\n",
    "    w_ex[w_ex<prune_smaller_than] = 0\n",
    "    w_in[w_in<prune_smaller_than] = 0\n",
    "\n",
    "    # Plot weight matrix interactions as a sanity check. Should be an 'arch' of inhibition, leaving the suppressing areas far from the injection site\n",
    "\n",
    "    intrinsic_input = np.tile(450., N_ex)\n",
    "\n",
    "    injection_site = I_init_pos\n",
    "\n",
    "    # As before, connection weight matrices, this time between conjunctive layers and the excitatory layer\n",
    "\n",
    "    w_l = np.empty((N_ex,N_cj))\n",
    "    w_r = np.empty((N_ex,N_cj))\n",
    "\n",
    "    for c in range(N_cj):  \n",
    "        for e in range(N_ex):\n",
    "            # Minimum distance, this time between each conjunctive cell and the excitatory cell displaced 1 away (e +/- 1)\n",
    "            # Left is anticlockwise, therefore drives the cell immediately to the left\n",
    "            # Right is clockwise, therefore drives the cell immediately to the right\n",
    "            d1 = abs((e-1)/N_cj - c/N_ex)\n",
    "            d2 = abs((e-1)/N_cj - c/N_ex -1)\n",
    "            d3 = abs((e-1)/N_cj - c/N_ex +1)\n",
    "            d = min(abs(d1),abs(d2),abs(d3))\n",
    "            w_l[e,c] = base_cj * (np.exp(-(d)**2/2/sigma**2))\n",
    "\n",
    "            d1 = abs((e+1)/N_cj - c/N_ex)\n",
    "            d2 = abs((e+1)/N_cj - c/N_ex -1)\n",
    "            d3 = abs((e+1)/N_cj - c/N_ex +1)\n",
    "            d = min(abs(d1),abs(d2),abs(d3))\n",
    "            w_r[e,c] = base_cj * (np.exp(-(d)**2/2/sigma**2))\n",
    "\n",
    "    # Set all not the max to zero; makes sure the conjunctive cells only drive the immediate neighbour\n",
    "    # Still uses the Gaussian connection weight, just doesn't use the whole Gaussian (for now)\n",
    "\n",
    "    m = np.amax(w_l)\n",
    "    w_l[w_l<m] = 0\n",
    "    m = np.amax(w_r)\n",
    "    w_r[w_r<m] = 0\n",
    "\n",
    "    # Gaussian weight matrix for inhibitory->left conjunctive cells (if conjuctive_mode == 'negative')\n",
    "\n",
    "    w_in_l_cj_gauss = np.empty((N_cj,N_in))\n",
    "\n",
    "    for i in range(N_in):\n",
    "        for c in range(N_cj):  \n",
    "            # Minimum distance, this time between each conjunctive cell and the excitatory cell displaced 1 away (e +/- 1)\n",
    "            # Left is anticlockwise, therefore drives the cell immediately to the left\n",
    "            # Right is clockwise, therefore drives the cell immediately to the right\n",
    "            d1 = abs((c-cj_in_offset)/N_cj - i/N_in)\n",
    "            d2 = abs((c-cj_in_offset)/N_cj - i/N_in -1)\n",
    "            d3 = abs((c-cj_in_offset)/N_cj - i/N_in +1)\n",
    "            d = min(abs(d1),abs(d2),abs(d3))\n",
    "            w_in_l_cj_gauss[c,i] = w_in_cj * (np.exp(-(d)**2/2/in_cj_sigma**2))\n",
    "\n",
    "    w_in_l_cj_gauss = w_in_l_cj_gauss# - np.max(w_in_cj_gauss)\n",
    "\n",
    "    # Very small weights become 0\n",
    "\n",
    "    w_in_l_cj_gauss[w_in_l_cj_gauss<prune_smaller_than] = 0\n",
    "    w_in_l_cj_gauss[w_in_l_cj_gauss<prune_smaller_than] = 0\n",
    "\n",
    "    # Gaussian weight matrix for inhibitory->right conjunctive cells (if conjuctive_mode == 'negative')\n",
    "\n",
    "    w_in_r_cj_gauss = np.empty((N_cj,N_in))\n",
    "\n",
    "    for i in range(N_in):\n",
    "        for c in range(N_cj):  \n",
    "            # Minimum distance, this time between each conjunctive cell and the excitatory cell displaced 1 away (e +/- 1)\n",
    "            # Left is anticlockwise, therefore drives the cell immediately to the left\n",
    "            # Right is clockwise, therefore drives the cell immediately to the right\n",
    "            d1 = abs((c+cj_in_offset)/N_cj - i/N_in)\n",
    "            d2 = abs((c+cj_in_offset)/N_cj - i/N_in -1)\n",
    "            d3 = abs((c+cj_in_offset)/N_cj - i/N_in +1)\n",
    "            d = min(abs(d1),abs(d2),abs(d3))\n",
    "            w_in_r_cj_gauss[c,i] = w_in_cj * (np.exp(-(d)**2/2/in_cj_sigma**2))\n",
    "\n",
    "    w_in_r_cj_gauss = w_in_r_cj_gauss# - np.max(w_in_cj_gauss)\n",
    "\n",
    "    # Very small weights become 0\n",
    "\n",
    "    w_in_r_cj_gauss[w_in_r_cj_gauss<prune_smaller_than] = 0\n",
    "    w_in_r_cj_gauss[w_in_r_cj_gauss<prune_smaller_than] = 0\n",
    "\n",
    "    ## Wire everything up\n",
    "\n",
    "    for i in range(rings):\n",
    "\n",
    "        # Excitatory and inhibitory set to connect all to all, using the prior calculated weight matrix\n",
    "\n",
    "        exc_2_inh = sim.Connect(exc[i],inh[i],'all_to_all',syn_spec={'weight': w_ex, 'delay': delay})\n",
    "        inh_2_exc = sim.Connect(inh[i],exc[i],'all_to_all',syn_spec={'weight': -w_in, 'delay': delay})\n",
    "\n",
    "        # Conjunctive layers connecting to the excitatory layer, with weights\n",
    "\n",
    "        l_2_exc = sim.Connect(l[i],exc[i],'all_to_all',syn_spec={'weight': w_l, 'delay': delay})\n",
    "        r_2_exc = sim.Connect(r[i],exc[i],'all_to_all',syn_spec={'weight': w_r, 'delay': delay})\n",
    "\n",
    "        if conjunctive_mode == 'positive':\n",
    "\n",
    "            # Excitatory connecting one-to-one to both conjunctive layers, with fixed weight.  A 'coincidence detector'.\n",
    "\n",
    "            exc_2_l = sim.Connect(exc[i],l[i],'one_to_one',syn_spec={'weight': w_ex_cj, 'delay': delay})\n",
    "            exc_2_r = sim.Connect(exc[i],r[i],'one_to_one',syn_spec={'weight': w_ex_cj, 'delay': delay})\n",
    "\n",
    "        elif conjunctive_mode == 'negative':\n",
    "\n",
    "            # Inhibitory connecting one-all_to_all-one to both conjunctive layers, with inverse Gaussian weights\n",
    "\n",
    "            inh_2_l = sim.Connect(inh[i],l[i],'all_to_all',syn_spec={'weight': -w_in_l_cj_gauss, 'delay': delay})\n",
    "            inh_2_r = sim.Connect(inh[i],r[i],'all_to_all',syn_spec={'weight': -w_in_r_cj_gauss, 'delay': delay})\n",
    "\n",
    "        elif conjunctive_mode == 'both':\n",
    "\n",
    "            exc_2_l = sim.Connect(exc[i],l[i],'one_to_one',syn_spec={'weight': w_ex_cj, 'delay': delay})\n",
    "            exc_2_r = sim.Connect(exc[i],r[i],'one_to_one',syn_spec={'weight': w_ex_cj, 'delay': delay})\n",
    "\n",
    "            inh_2_l = sim.Connect(inh[i],l[i],'all_to_all',syn_spec={'weight': -w_in_l_cj_gauss, 'delay': delay})\n",
    "            inh_2_r = sim.Connect(inh[i],r[i],'all_to_all',syn_spec={'weight': -w_in_r_cj_gauss, 'delay': delay})\n",
    "\n",
    "    ## Wire everything up\n",
    "\n",
    "    # Connect a N-wide window of the ring to each principle axis cell\n",
    "\n",
    "    windows = []\n",
    "\n",
    "    for ring in exc:\n",
    "\n",
    "        for i in range(0, N_ex, window_size):\n",
    "\n",
    "            window = ring[((i+rp_offset) % N_ex):((i+rp_offset) % N_ex) + window_size]\n",
    "\n",
    "            if i + rp_offset + window_size > N_ex and len(window) < window_size:\n",
    "\n",
    "                window = window + ring[0:rp_offset]\n",
    "\n",
    "            windows.append(window)\n",
    "\n",
    "    for i in range(rings):\n",
    "\n",
    "        for j in range(N_pa_cells_per_ring):\n",
    "\n",
    "            sim.Connect(windows[i*N_pa_cells_per_ring+j], [pa_cells[i][j]],'all_to_all',syn_spec={'weight': w_ex_pa, 'delay': delay})\n",
    "\n",
    "    total_pa_cells = N_pa_cells_per_ring * rings\n",
    "\n",
    "    cell_indices = np.zeros(shape = (N_pyramidals))\n",
    "    target_cells = np.zeros(shape = (N_pyramidals))\n",
    "    source_pa_cells = np.zeros(shape = (rings, N_pyramidals))\n",
    "    source_pa_cell_indices = np.zeros(shape = (rings, N_pyramidals))\n",
    "\n",
    "    in_range = True\n",
    "\n",
    "    for r1 in (x for x in range(N_pa_cells_per_ring) if in_range is True): # Ring 1\n",
    "\n",
    "        for r2 in (y for y in range(N_pa_cells_per_ring) if in_range is True): # Ring 2\n",
    "\n",
    "            for r3 in (z for z in range(N_pa_cells_per_ring) if in_range is True): # Ring 3\n",
    "\n",
    "                #cell_index = (((r1 + rp_offset) % N_pa_cells_per_ring) * N_pa_cells_per_ring ** 2) + (((r2 + rp_offset) % N_pa_cells_per_ring) * N_pa_cells_per_ring) + ((r3 + rp_offset) % N_pa_cells_per_ring) # Steps from 0 to max\n",
    "                cell_index = (r1 * N_pa_cells_per_ring ** 2) + (r2 * N_pa_cells_per_ring) + r3 # Steps from 0 to max\n",
    "\n",
    "                if cell_index != N_pyramidals:\n",
    "\n",
    "                    target_cell = pyramidal_cells[cell_index]\n",
    "\n",
    "                    sim.Connect([pa_cells[0][r1]], [target_cell],'all_to_all',syn_spec={'weight': w_pa_py, 'delay': delay})\n",
    "                    sim.Connect([pa_cells[1][r2]], [target_cell],'all_to_all',syn_spec={'weight': w_pa_py, 'delay': delay})\n",
    "                    sim.Connect([pa_cells[2][r3]], [target_cell],'all_to_all',syn_spec={'weight': w_pa_py, 'delay': delay})\n",
    "\n",
    "                    # Gather up data for Pandas, to be used later in grid cell evalutation\n",
    "\n",
    "                    cell_indices[cell_index] = cell_index\n",
    "                    target_cells[cell_index] = target_cell\n",
    "                    source_pa_cells[0][cell_index] = pa_cells[0][r1]\n",
    "                    source_pa_cells[1][cell_index] = pa_cells[1][r2]\n",
    "                    source_pa_cells[2][cell_index] = pa_cells[2][r3]\n",
    "                    source_pa_cell_indices[0][cell_index] = r1\n",
    "                    source_pa_cell_indices[1][cell_index] = r2\n",
    "                    source_pa_cell_indices[2][cell_index] = r3\n",
    "\n",
    "    #             else:\n",
    "\n",
    "    #                 in_range = False\n",
    "\n",
    "    pa_to_pyramidal_connections = pd.DataFrame({'Target Cell Index': cell_indices,\n",
    "                                                'Target Pyramidal Cell': target_cells,\n",
    "                                                'Ring 1 Index': source_pa_cell_indices[0],\n",
    "                                                'Ring 2 Index': source_pa_cell_indices[1],\n",
    "                                                'Ring 3 Index': source_pa_cell_indices[2],\n",
    "                                                'Ring 1 PA Cell': source_pa_cells[0],\n",
    "                                                'Ring 2 PA Cell': source_pa_cells[1],\n",
    "                                                'Ring 3 PA Cell': source_pa_cells[2],})\n",
    "\n",
    "    # Now do the same but in the opposite direction; assign each unique combination of RP cells an incoming 'grid input cell'\n",
    "    # that can be driven by external input cues\n",
    "\n",
    "    # For convenience, and to save modelling an extra population of 'pass through' cells, input devices current synapse directly onto the \n",
    "    # excitatory ring, at the midpoint of the RP receptive field\n",
    "\n",
    "    # The non-existent input RP cells are given here as placeholders, for managing input to the ring in the format plausible for \n",
    "    # downstream brain areas to be aware of; it is assumed that the state of the rings themselves is too granular\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    total_pa_cells = N_pa_cells_per_ring * rings\n",
    "\n",
    "    source_cell_indices = np.zeros(shape = (N_pyramidals))\n",
    "    source_cells = np.zeros(shape = (N_pyramidals))\n",
    "    target_ring_cells = np.zeros(shape = (rings, N_pyramidals))\n",
    "    target_ring_cell_indices = np.zeros(shape = (rings, N_pyramidals))\n",
    "    target_virtual_rp = np.zeros(shape = (rings, N_pyramidals))\n",
    "\n",
    "    in_range = True\n",
    "\n",
    "    for r1 in (x for x in range(N_pa_cells_per_ring) if in_range is True): # Ring 1\n",
    "\n",
    "        for r2 in (y for y in range(N_pa_cells_per_ring) if in_range is True): # Ring 2\n",
    "\n",
    "            for r3 in (z for z in range(N_pa_cells_per_ring) if in_range is True): # Ring 3\n",
    "\n",
    "                #source_cell_index = (((r1 + rp_offset) % N_pa_cells_per_ring) * N_pa_cells_per_ring ** 2) + (((r2 + rp_offset) % N_pa_cells_per_ring) * N_pa_cells_per_ring) + ((r3 + rp_offset) % N_pa_cells_per_ring) # Steps from 0 to max\n",
    "                source_cell_index = (r1 * N_pa_cells_per_ring ** 2) + (r2 * N_pa_cells_per_ring) + r3 # Steps from 0 to max\n",
    "\n",
    "                if cell_index != N_pyramidals:\n",
    "\n",
    "                    source_cell = input_grid_devices[source_cell_index]\n",
    "\n",
    "                    target_cell_index_r1 = (r1 + 1) * window_size - (window_size // 2) - 1\n",
    "                    target_cell_index_r2 = (r2 + 1) * window_size - (window_size // 2) - 1\n",
    "                    target_cell_index_r3 = (r3 + 1) * window_size - (window_size // 2) - 1\n",
    "\n",
    "                    target_cell_r1 = exc[0][target_cell_index_r1]\n",
    "                    target_cell_r2 = exc[1][target_cell_index_r2]\n",
    "                    target_cell_r3 = exc[2][target_cell_index_r3]\n",
    "\n",
    "                    sim.Connect([source_cell], [target_cell_r1], 'all_to_all')#, syn_spec={'weight': w_in_pa, 'delay': delay})\n",
    "                    sim.Connect([source_cell], [target_cell_r2], 'all_to_all')#, syn_spec={'weight': w_in_pa, 'delay': delay})\n",
    "                    sim.Connect([source_cell], [target_cell_r3], 'all_to_all')#, syn_spec={'weight': w_in_pa, 'delay': delay})\n",
    "\n",
    "                    # Gather up data for Pandas, to be used later in grid cell evalutation\n",
    "\n",
    "                    source_cell_indices[source_cell_index] = source_cell_index\n",
    "                    source_cells[source_cell_index] = source_cell\n",
    "                    target_virtual_rp[0][source_cell_index] = r1\n",
    "                    target_virtual_rp[1][source_cell_index] = r2\n",
    "                    target_virtual_rp[2][source_cell_index] = r3\n",
    "                    target_ring_cells[0][source_cell_index] = target_cell_r1\n",
    "                    target_ring_cells[1][source_cell_index] = target_cell_r2\n",
    "                    target_ring_cells[2][source_cell_index] = target_cell_r3\n",
    "                    target_ring_cell_indices[0][source_cell_index] = target_cell_index_r1\n",
    "                    target_ring_cell_indices[1][source_cell_index] = target_cell_index_r2\n",
    "                    target_ring_cell_indices[2][source_cell_index] = target_cell_index_r3\n",
    "\n",
    "    #             else:\n",
    "\n",
    "    #                 in_range = False\n",
    "\n",
    "    input_device_to_ring_cells_connections = pd.DataFrame({ 'Source Device Index': source_cell_indices,\n",
    "                                                            'Source Device': source_cells,\n",
    "                                                            'Ring 1 Virtual RP' : target_virtual_rp[0],\n",
    "                                                            'Ring 2 Virtual RP' : target_virtual_rp[1],\n",
    "                                                            'Ring 3 Virtual RP' : target_virtual_rp[2],\n",
    "                                                            'Ring 1 Index': target_ring_cell_indices[0],\n",
    "                                                            'Ring 2 Index': target_ring_cell_indices[1],\n",
    "                                                            'Ring 3 Index': target_ring_cell_indices[2],\n",
    "                                                            'Ring 1 Cell': target_ring_cells[0],\n",
    "                                                            'Ring 2 Cell': target_ring_cells[1],\n",
    "                                                            'Ring 3 Cell': target_ring_cells[2],})\n",
    "\n",
    "    sim.GetConnections([source_cell])\n",
    "\n",
    "    ## Record spike activity\n",
    "\n",
    "    # Single spike detectors, connected to all cells in the given population in a given ring\n",
    "    # 'params' dictionary describes which variables to log; gid: global neuron id, time is in milliseconds\n",
    "\n",
    "    exc_spikes = []\n",
    "    inh_spikes = []\n",
    "    pa_spikes = []\n",
    "    left_cj_spikes = []\n",
    "    right_cj_spikes = []\n",
    "\n",
    "    for i in range(rings):\n",
    "\n",
    "        exc_spikes.append(sim.Create(\"spike_detector\", 1, params={\"withgid\": True,\"withtime\": True}))\n",
    "        sim.Connect(exc[i],exc_spikes[i])\n",
    "\n",
    "        inh_spikes.append(sim.Create(\"spike_detector\", 1, params={\"withgid\": True,\"withtime\": True}))\n",
    "        sim.Connect(inh[i],inh_spikes[i])\n",
    "\n",
    "        pa_spikes.append(sim.Create(\"spike_detector\", 1, params={\"withgid\": True,\"withtime\": True}))\n",
    "        sim.Connect(pa_cells[i],pa_spikes[i])\n",
    "\n",
    "        left_cj_spikes.append(sim.Create(\"spike_detector\", 1, params={\"withgid\": True,\"withtime\": True}))\n",
    "        sim.Connect(l[i],left_cj_spikes[i])\n",
    "\n",
    "        right_cj_spikes.append(sim.Create(\"spike_detector\", 1, params={\"withgid\": True,\"withtime\": True}))\n",
    "        sim.Connect(r[i],right_cj_spikes[i])\n",
    "\n",
    "    pyramidal_spikes = sim.Create(\"spike_detector\", 1, params={\"withgid\": True,\"withtime\": True})\n",
    "    sim.Connect(pyramidal_cells,pyramidal_spikes)\n",
    "\n",
    "    ## Input to the network\n",
    "\n",
    "    ## PredNet representations\n",
    "\n",
    "    representation_root_folder = 'data/NRP_reps/'\n",
    "\n",
    "    representation_folders = [ \"playground_ordered_testset1\",\n",
    "                               \"playground_ordered_testset2\",\n",
    "                               \"playground_ordered_testset3\",\n",
    "                               \"playground_ordered_testset4\",\n",
    "                               \"playground_ordered_testset5\",\n",
    "                               \"playground_ordered_testset6\" ]\n",
    "\n",
    "    representations = [np.load(representation_root_folder + folder + \"/both/representations.npy\") for folder in representation_folders]\n",
    "\n",
    "    representations_per_dataset = [reps.shape[0] for reps in representations]\n",
    "\n",
    "    representations = np.vstack(representations)\n",
    "\n",
    "    ### Position data\n",
    "\n",
    "    # Two options for getting input data for the network. In all cases, position data is loaded/generated, then velocity derived in later cells\n",
    "    # 'spiral': original spiral trajectory\n",
    "    # 'rat': load one of the Sargolini group's datasets, from real rat foraging task data\n",
    "\n",
    "    if spiral_or_rat == 'spiral':\n",
    "\n",
    "        number_of_turns = 300\n",
    "        numT = number_of_turns * 1000 * np.pi\n",
    "        print(numT/1000)\n",
    "        dt = 20\n",
    "        t = np.arange(0,sim_len,dt)*1.\n",
    "        time = [i * 1. for i in t if i < sim_len]\n",
    "        ts = np.arange(0,numT,numT/len(t))/1000.\n",
    "        V = 30\n",
    "        dr = 5\n",
    "        ph = -np.sqrt(((V * (4*np.pi) * ts) / dr))\n",
    "        ra =  np.sqrt(((V * dr * ts) / np.pi))\n",
    "\n",
    "        pos_x = ra * np.cos(ph) \n",
    "        pos_y = ra * np.sin(ph)\n",
    "\n",
    "    elif spiral_or_rat == 'rat':\n",
    "\n",
    "        # Roughly 92 20ms timesteps per representation\n",
    "\n",
    "        start_sample = 0\n",
    "        N_data_samples = 4000\n",
    "\n",
    "        from scipy.ndimage import median_filter, gaussian_filter\n",
    "\n",
    "        # Load rat trajectory data from file\n",
    "\n",
    "        data_folders = ['NRP_2021_testset1', 'NRP_2021_testset2', 'NRP_2021_testset3',\n",
    "                        'NRP_2021_testset4', 'NRP_2021_testset5', 'NRP_2021_testset6']\n",
    "\n",
    "        #data_folders = ['NRP_2021_testset1', 'NRP_2021_testset2']\n",
    "\n",
    "        rat_dataset = [np.loadtxt('data/NRP_data/{}/raw_pose.csv'.format(folder), skiprows = 1, delimiter = ',') for folder in data_folders]\n",
    "\n",
    "        # Find where each dataset ends. Timesteps also reset at these points.\n",
    "\n",
    "        dataset_ends = [len(testset) for testset in rat_dataset]\n",
    "\n",
    "        # Find where they will end in the combined dataset\n",
    "\n",
    "        dataset_ends_cumulative = [sum(dataset_ends[:i]) - 1 for i in range(1,len(dataset_ends)+1)]\n",
    "\n",
    "        # Apply the required fixes as per the README\n",
    "\n",
    "        rat_dataset[2][:,1] = rat_dataset[2][:,1] - 3 # Testset 3 needs adjusting -3m X and -6.1 Y\n",
    "        rat_dataset[2][:,2] = rat_dataset[2][:,2] - 6.1# Testset 3 needs adjusting -3m X and -6.1 Y\n",
    "        rat_dataset[3][:,2] = rat_dataset[3][:,2] - 6.1# Testset 4 needs adjusting -6.1 Y\n",
    "\n",
    "        rat_dataset = np.vstack(rat_dataset)\n",
    "\n",
    "        # Find the actual timestamps where each dataset end\n",
    "\n",
    "        dataset_max_timestamps = rat_dataset[dataset_ends_cumulative, 0]\n",
    "\n",
    "        # For each window of data, add on the previous maximum value; this should give a combined dataset with a monotonically increasing timestep\n",
    "\n",
    "        dataset_cumulative_max_timestamps = [sum(dataset_max_timestamps[:i]) for i in range(1,len(dataset_max_timestamps)+1)]\n",
    "\n",
    "        rat_dataset_timesteps_in_sequence = rat_dataset.copy()\n",
    "\n",
    "        rat_dataset_timesteps_in_sequence[dataset_ends_cumulative[0]+1:, 0] = np.hstack([rat_dataset[i+1:j+1, 0] + m for i, j, m in zip(dataset_ends_cumulative[:-1], dataset_ends_cumulative[1:], dataset_cumulative_max_timestamps[:-1])])\n",
    "\n",
    "        assert np.all(rat_dataset_timesteps_in_sequence[1:, 0] > rat_dataset_timesteps_in_sequence[:-1, 0])\n",
    "\n",
    "        # Now do the same for the representations\n",
    "\n",
    "        rat_representation_timestamps = [np.load('data/NRP_data/{}/representation_matched_poses.npy'.format(folder))[:rep_count, 0] for folder, rep_count in zip(data_folders, representations_per_dataset)]\n",
    "\n",
    "        # Find where each dataset ends. Timesteps also reset at these points.\n",
    "\n",
    "        dataset_ends = [len(testset) for testset in rat_representation_timestamps]\n",
    "\n",
    "        # Find where they will end in the combined dataset\n",
    "\n",
    "        dataset_ends_cumulative = [sum(dataset_ends[:i]) - 1 for i in range(1,len(dataset_ends)+1)]\n",
    "\n",
    "        rat_representation_timestamps = np.hstack(rat_representation_timestamps)\n",
    "\n",
    "        # Find the actual timestamps where each dataset end\n",
    "\n",
    "        dataset_max_timestamps = rat_representation_timestamps[dataset_ends_cumulative]\n",
    "\n",
    "        # For each window of data, add on the previous maximum value; this should give a combined dataset with a monotonically increasing timestep\n",
    "\n",
    "        dataset_cumulative_max_timestamps = [sum(dataset_max_timestamps[:i]) for i in range(1,len(dataset_max_timestamps)+1)]\n",
    "\n",
    "        rat_representations_timesteps_in_sequence = rat_representation_timestamps.copy()\n",
    "\n",
    "        rat_representations_timesteps_in_sequence[dataset_ends_cumulative[0]+1:] = np.hstack([rat_representation_timestamps[i+1:j+1] + m for i, j, m in zip(dataset_ends_cumulative[:-1], dataset_ends_cumulative[1:], dataset_cumulative_max_timestamps[:-1])])\n",
    "\n",
    "        assert np.all(rat_representations_timesteps_in_sequence[1:] > rat_representations_timesteps_in_sequence[:-1])\n",
    "\n",
    "        rat_dataset_timesteps_in_sequence = rat_dataset_timesteps_in_sequence[start_sample:start_sample+N_data_samples]\n",
    "        #rat_representations_timesteps_in_sequence = rat_representations_timesteps_in_sequence[:N_representations]\n",
    "        rat_representations_timesteps_in_sequence = rat_representations_timesteps_in_sequence[(rat_representations_timesteps_in_sequence > rat_dataset_timesteps_in_sequence[0,0]) & (rat_representations_timesteps_in_sequence < rat_dataset_timesteps_in_sequence[-1,0])]\n",
    "\n",
    "        # Now find where injections are required\n",
    "\n",
    "        rat_injection_index = np.searchsorted(rat_dataset_timesteps_in_sequence[:, 0], rat_representations_timesteps_in_sequence)\n",
    "\n",
    "        # Get rid of any redundant injections (only 2 at last check, so doesn't seem to be a systematic issue)\n",
    "\n",
    "        rat_injection_index = rat_injection_index[np.nonzero(np.diff(rat_injection_index) > 0)]\n",
    "\n",
    "        assert np.all(rat_injection_index[1:] > rat_injection_index[:-1])\n",
    "\n",
    "        # Trim to desired interval\n",
    "\n",
    "        # print(max(rat_dataset_timesteps_in_sequence[:,0]))\n",
    "        # print(max(rat_representations_timesteps_in_sequence))\n",
    "        # print(max(rat_injection_index))\n",
    "\n",
    "        # rat_dataset_timesteps_in_sequence = rat_dataset_timesteps_in_sequence[:N_data_samples]\n",
    "        # rat_representations_timesteps_in_sequence = rat_representations_timesteps_in_sequence[:N_representations]\n",
    "    #     rat_injection_index = rat_injection_index[rat_injection_index < int(max(rat_representations_timesteps_in_sequence))]\n",
    "\n",
    "    #     print(max(rat_dataset_timesteps_in_sequence[:,0]))\n",
    "    #     print(max(rat_representations_timesteps_in_sequence))\n",
    "    #     print(max(rat_injection_index))\n",
    "\n",
    "\n",
    "        # Create variables for velocity calculation later\n",
    "\n",
    "        pos_x = rat_dataset_timesteps_in_sequence[:,1]\n",
    "        #pos_x = gaussian_filter(pos_x, sigma = smooth_sigma, mode = 'nearest')\n",
    "        pos_y = rat_dataset_timesteps_in_sequence[:,2]\n",
    "        #pos_y = gaussian_filter(pos_y, sigma = smooth_sigma, mode = 'nearest')\n",
    "\n",
    "        theta = rat_dataset_timesteps_in_sequence[:,3]\n",
    "\n",
    "        #print(f\"Original count {len(pos_x)}\")\n",
    "        #timestamps = np.arange(0, len(rat_dataset_timesteps_in_sequence)) / 50 # Hz\n",
    "        timestamps = rat_dataset_timesteps_in_sequence[:, 0] - np.min(rat_dataset_timesteps_in_sequence[:, 0])\n",
    "\n",
    "        timestamps = timestamps / 1000000000 # Get from nanoseconds to seconds\n",
    "\n",
    "        representation_timestamps = timestamps[rat_injection_index]\n",
    "\n",
    "        #print(f\"Representations: {len(representation_timestamps)}\")\n",
    "\n",
    "        #print(np.diff(timestamps))\n",
    "        #print(np.mean(np.diff(timestamps)))\n",
    "        #print(np.mean(np.diff(representation_timestamps)))\n",
    "\n",
    "        time = timestamps * 1000 # Get from seconds to milliseconds\n",
    "\n",
    "        representation_times = time[rat_injection_index]\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError\n",
    "\n",
    "    ### Calculate velocity\n",
    "\n",
    "    # Calculate velocity to convert to step current\n",
    "    # As with head direction network, small values are boosted, but values that were 0 or less are set back to 0\n",
    "\n",
    "    vel_x = np.diff(pos_x)\n",
    "    vel_y = np.diff(pos_y)\n",
    "\n",
    "    if calibration_mode:\n",
    "\n",
    "        vel_x = np.zeros_like(vel_x)\n",
    "        vel_y = np.zeros_like(vel_y)\n",
    "\n",
    "    vel_x,vel_y = vel_x*I_vel, vel_y*I_vel\n",
    "\n",
    "    # Now we split this across the rings according to their direction of travel\n",
    "\n",
    "    # Axes are:\n",
    "    # Y, as usual\n",
    "    # X_plus_60 (60 degree offset from Y around origin, diagonal bottom-right to upper-left)\n",
    "    # X_plus_120 (120 degree offset from Y around origin, diagonal bottom-left to upper-right)\n",
    "\n",
    "    velocity_magnitude = np.sqrt(vel_x ** 2 + vel_y ** 2)\n",
    "\n",
    "    #if velocity_threshold:\n",
    "\n",
    "    #    velocity_magnitude = velocity_magnitude + minimum_velocity\n",
    "\n",
    "    #    velocity_magnitude[velocity_magnitude < minimum_velocity] = 0.\n",
    "\n",
    "    velocity_angle = np.arctan2(vel_y, vel_x)\n",
    "\n",
    "    # Calculate overall components for use in later analysis\n",
    "\n",
    "    Y_input_total = velocity_magnitude * np.cos(velocity_angle)\n",
    "\n",
    "    Y_plus_60_offset = np.radians(60)\n",
    "    Y_plus_120_offset = np.radians(120)\n",
    "\n",
    "    Y_plus_60_input_total = velocity_magnitude * np.cos(velocity_angle - Y_plus_60_offset)\n",
    "    Y_plus_120_input_total = velocity_magnitude * np.cos(velocity_angle - Y_plus_120_offset)\n",
    "\n",
    "    # Now split into positive and negative to feed to left and right conjunctive cells respectively\n",
    "\n",
    "    velocity_component = np.cos(velocity_angle)\n",
    "\n",
    "    positive_component = velocity_component.copy()\n",
    "    negative_component = velocity_component.copy()\n",
    "\n",
    "    positive_component[positive_component < 0] = 0.\n",
    "    negative_component[negative_component > 0] = 0.\n",
    "\n",
    "    Y_input_l = velocity_magnitude * positive_component\n",
    "    Y_input_r = velocity_magnitude * negative_component\n",
    "\n",
    "    Y_input_r = -Y_input_r\n",
    "\n",
    "    Y_input_l_compliment = velocity_magnitude - Y_input_l\n",
    "    Y_input_r_compliment = velocity_magnitude - Y_input_r\n",
    "\n",
    "    Y_input_l = velocity_magnitude + Y_input_l + Y_input_r_compliment + minimum_input\n",
    "    Y_input_r = velocity_magnitude + Y_input_r + Y_input_l_compliment + minimum_input\n",
    "\n",
    "\n",
    "    velocity_component_60 = np.cos(velocity_angle - Y_plus_60_offset)\n",
    "\n",
    "    positive_component_60 = velocity_component_60.copy()\n",
    "    negative_component_60 = velocity_component_60.copy()\n",
    "\n",
    "    positive_component_60[positive_component_60 < 0] = 0.\n",
    "    negative_component_60[negative_component_60 > 0] = 0.\n",
    "\n",
    "    Y_plus_60_input_l = velocity_magnitude * positive_component_60 # np.cos(positive_angle - Y_plus_60_offset)\n",
    "    Y_plus_60_input_r = velocity_magnitude * negative_component_60 # np.cos(negative_angle - Y_plus_60_offset)\n",
    "\n",
    "    Y_plus_60_input_r = -Y_plus_60_input_r\n",
    "\n",
    "    Y_plus_60_input_l_compliment = velocity_magnitude - Y_plus_60_input_l\n",
    "    Y_plus_60_input_r_compliment = velocity_magnitude - Y_plus_60_input_r\n",
    "\n",
    "    Y_plus_60_input_l = velocity_magnitude + Y_plus_60_input_l + Y_plus_60_input_r_compliment + minimum_input\n",
    "    Y_plus_60_input_r = velocity_magnitude + Y_plus_60_input_r + Y_plus_60_input_l_compliment + minimum_input\n",
    "\n",
    "\n",
    "    velocity_component_120 = np.cos(velocity_angle - Y_plus_120_offset)\n",
    "\n",
    "    positive_component_120 = velocity_component_120.copy()\n",
    "    negative_component_120 = velocity_component_120.copy()\n",
    "\n",
    "    positive_component_120[positive_component_120 < 0] = 0.\n",
    "    negative_component_120[negative_component_120 > 0] = 0.\n",
    "\n",
    "    Y_plus_120_input_l = velocity_magnitude * positive_component_120 # np.cos(positive_angle - Y_plus_120_offset)\n",
    "    Y_plus_120_input_r = velocity_magnitude * negative_component_120 # np.cos(negative_angle - Y_plus_120_offset)\n",
    "\n",
    "    Y_plus_120_input_r = -Y_plus_120_input_r\n",
    "\n",
    "    Y_plus_120_input_l_compliment = velocity_magnitude - Y_plus_120_input_l\n",
    "    Y_plus_120_input_r_compliment = velocity_magnitude - Y_plus_120_input_r\n",
    "\n",
    "    Y_plus_120_input_l = velocity_magnitude + Y_plus_120_input_l + Y_plus_120_input_r_compliment + minimum_input\n",
    "    Y_plus_120_input_r = velocity_magnitude + Y_plus_120_input_r + Y_plus_120_input_l_compliment + minimum_input\n",
    "\n",
    "\n",
    "    if not stochastic_input_current:\n",
    "    \n",
    "        # Connect y input to conjunctive layers\n",
    "\n",
    "        y_l_input = sim.Create('step_current_generator', 1)\n",
    "        sim.SetStatus(y_l_input,{'amplitude_times': time[1:],'amplitude_values': Y_input_l})\n",
    "\n",
    "        y_r_input = sim.Create('step_current_generator', 1)\n",
    "        sim.SetStatus(y_r_input,{'amplitude_times': time[1:],'amplitude_values': Y_input_r})\n",
    "\n",
    "        sim.Connect(y_l_input,l[0],'all_to_all')\n",
    "        sim.Connect(y_r_input,r[0],'all_to_all')\n",
    "\n",
    "        # Connect y_plus_60 input to conjunctive layers\n",
    "\n",
    "        Y_plus_60_l_input = sim.Create('step_current_generator', 1)\n",
    "        sim.SetStatus(Y_plus_60_l_input,{'amplitude_times': time[1:],'amplitude_values': Y_plus_60_input_l})\n",
    "        Y_plus_60_r_input = sim.Create('step_current_generator', 1)\n",
    "        sim.SetStatus(Y_plus_60_r_input,{'amplitude_times': time[1:],'amplitude_values': Y_plus_60_input_r})\n",
    "\n",
    "        sim.Connect(Y_plus_60_l_input,l[1],'all_to_all')\n",
    "        sim.Connect(Y_plus_60_r_input,r[1],'all_to_all')\n",
    "\n",
    "        # Connect y_plus_120 input to conjunctive layers\n",
    "\n",
    "        Y_plus_120_l_input = sim.Create('step_current_generator', 1)\n",
    "        sim.SetStatus(Y_plus_120_l_input,{'amplitude_times': time[1:],'amplitude_values': Y_plus_120_input_l})\n",
    "        Y_plus_120_r_input = sim.Create('step_current_generator', 1)\n",
    "        sim.SetStatus(Y_plus_120_r_input,{'amplitude_times': time[1:],'amplitude_values': Y_plus_120_input_r})\n",
    "\n",
    "        sim.Connect(Y_plus_120_l_input,l[2],'all_to_all')\n",
    "        sim.Connect(Y_plus_120_r_input,r[2],'all_to_all')\n",
    "        \n",
    "        input_current_sigma = None\n",
    "        \n",
    "    elif stochastic_input_current:\n",
    "        \n",
    "        N_samples = len(Y_input_l)\n",
    "        \n",
    "        input_current_sigma = np.mean(np.diff(Y_input_l)) / 2\n",
    "        \n",
    "        Y_input_l = Y_input_l + input_rng.normal(scale = input_current_sigma, size = N_samples)\n",
    "        Y_input_r = Y_input_r + input_rng.normal(scale = input_current_sigma, size = N_samples)\n",
    "        Y_plus_60_input_l = Y_plus_60_input_l + input_rng.normal(scale = input_current_sigma, size = N_samples)\n",
    "        Y_plus_60_input_r = Y_plus_60_input_r + input_rng.normal(scale = input_current_sigma, size = N_samples)\n",
    "        Y_plus_120_input_l = Y_plus_120_input_l + input_rng.normal(scale = input_current_sigma, size = N_samples)\n",
    "        Y_plus_120_input_l = Y_plus_120_input_l + input_rng.normal(scale = input_current_sigma, size = N_samples)\n",
    "        \n",
    "        # Connect y input to conjunctive layers\n",
    "\n",
    "        y_l_input = sim.Create('step_current_generator', 1)\n",
    "        sim.SetStatus(y_l_input,{'amplitude_times': time[1:],'amplitude_values': Y_input_l})\n",
    "\n",
    "        y_r_input = sim.Create('step_current_generator', 1)\n",
    "        sim.SetStatus(y_r_input,{'amplitude_times': time[1:],'amplitude_values': Y_input_r})\n",
    "\n",
    "        sim.Connect(y_l_input,l[0],'all_to_all')\n",
    "        sim.Connect(y_r_input,r[0],'all_to_all')\n",
    "\n",
    "        # Connect y_plus_60 input to conjunctive layers\n",
    "\n",
    "        Y_plus_60_l_input = sim.Create('step_current_generator', 1)\n",
    "        sim.SetStatus(Y_plus_60_l_input,{'amplitude_times': time[1:],'amplitude_values': Y_plus_60_input_l})\n",
    "        Y_plus_60_r_input = sim.Create('step_current_generator', 1)\n",
    "        sim.SetStatus(Y_plus_60_r_input,{'amplitude_times': time[1:],'amplitude_values': Y_plus_60_input_r})\n",
    "\n",
    "        sim.Connect(Y_plus_60_l_input,l[1],'all_to_all')\n",
    "        sim.Connect(Y_plus_60_r_input,r[1],'all_to_all')\n",
    "\n",
    "        # Connect y_plus_120 input to conjunctive layers\n",
    "\n",
    "        Y_plus_120_l_input = sim.Create('step_current_generator', 1)\n",
    "        sim.SetStatus(Y_plus_120_l_input,{'amplitude_times': time[1:],'amplitude_values': Y_plus_120_input_l})\n",
    "        Y_plus_120_r_input = sim.Create('step_current_generator', 1)\n",
    "        sim.SetStatus(Y_plus_120_r_input,{'amplitude_times': time[1:],'amplitude_values': Y_plus_120_input_r})\n",
    "\n",
    "        sim.Connect(Y_plus_120_l_input,l[2],'all_to_all')\n",
    "        sim.Connect(Y_plus_120_r_input,r[2],'all_to_all')\n",
    "\n",
    "    ### Bump-forming current generator\n",
    "\n",
    "    # Inject current for a given duration to start the bump off\n",
    "\n",
    "    bump_init = sim.Create('step_current_generator', 1, params = {'amplitude_times':[0.1,0.1+I_init_dur],'amplitude_values':[I_init,0.0]})\n",
    "    sim.Connect(bump_init,[exc[0][I_init_pos]])\n",
    "    sim.Connect(bump_init,[exc[1][I_init_pos]])\n",
    "    sim.Connect(bump_init,[exc[2][I_init_pos]])\n",
    "\n",
    "    ## Run simulation in tandem with representation corrections\n",
    "\n",
    "    # Get the memory set up and data loaded\n",
    "    \n",
    "    sense_memories = [] # Save representations from PredNet\n",
    "    location_memories = [] # Save ring coordinates from NEST\n",
    "\n",
    "    recall_threshold = 0.8\n",
    "\n",
    "    history_timestep_window = 5\n",
    "\n",
    "    # Run simulation in small steps, injecting when required\n",
    "\n",
    "    # From the docs: Calling SetStatus() inside a RunManager() context or between Prepare() and Cleanup() will lead to unpredictable results.\n",
    "\n",
    "    time_deltas = np.diff(time).astype(int)\n",
    "\n",
    "    start_delay = 100\n",
    "\n",
    "    no_spike_timeout = 5\n",
    "\n",
    "    recalls = 0\n",
    "    new_memories = 0\n",
    "\n",
    "    correction_duration = 500. # 500.\n",
    "    correction_current = 450. # 450 is the sweet spot to apply corrections without wild spinning of the bump\n",
    "    confidence_scaling = False # Multiply correction_current by Pearson correlation\n",
    "\n",
    "    injection_type = \"mono\"\n",
    "\n",
    "    current_exc_state = np.zeros(shape = (rings, N_ex))\n",
    "    exc_state_history = np.zeros(shape = (len(timestamps), rings, N_ex))\n",
    "\n",
    "    current_rp_state = np.zeros(shape = (rings, N_pa_cells_per_ring))\n",
    "\n",
    "    injection_state_history = np.zeros_like(exc_state_history)\n",
    "\n",
    "    memory_state_history = []#pd.DataFrame(columns = (\"Timestep\", \"Memory Created\", \"Recalled Memory\", \n",
    "                           #                        \"Active Ring 1 RP\", \"Active Ring 2 RP\", \"Active Ring 3 RP\",\n",
    "                           #                        \"Recalled Ring 1 RP\", \"Recalled Ring 2 RP\", \"Recalled Ring 3 RP\"))\n",
    "\n",
    "    representation_index = 0\n",
    "\n",
    "    input_device = None\n",
    "\n",
    "    if simulate_or_load == 'simulate':\n",
    "\n",
    "        for time_delta, t, tick in zip(time_deltas, time, range(len(time))):\n",
    "\n",
    "            if input_device is not None and corrections == True and np.all(None not in current_most_active_rp) and t == representation_times[representation_index]:\n",
    "\n",
    "                if injection_type == 'mono':\n",
    "\n",
    "                    if not confidence_scaling:\n",
    "\n",
    "                        sim.SetStatus([input_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current, 0.0]})\n",
    "\n",
    "                    elif confidence_scaling and best_match_value is not None:\n",
    "\n",
    "                        sim.SetStatus([input_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current * best_match_value, 0.0]})\n",
    "\n",
    "                        best_match_value == None\n",
    "\n",
    "                elif injection_type == 'gaussian':\n",
    "\n",
    "                    left_device = input_device - 1\n",
    "                    right_device = input_device + 1\n",
    "\n",
    "                    if left_device not in input_grid_devices:\n",
    "\n",
    "                        left_device = input_grid_devices[-1]\n",
    "\n",
    "                    if right_device not in input_grid_devices:\n",
    "\n",
    "                        right_device = input_grid_devices[0]\n",
    "\n",
    "                    if not confidence_scaling:\n",
    "\n",
    "                        sim.SetStatus([input_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current, 0.0]})\n",
    "                        sim.SetStatus([left_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current, 0.0]})\n",
    "                        sim.SetStatus([right_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current, 0.0]})\n",
    "\n",
    "                    elif confidence_scaling and best_match_value is not None:\n",
    "\n",
    "                        sim.SetStatus([input_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current * best_match_value, 0.0]})\n",
    "                        sim.SetStatus([left_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current * best_match_value, 0.0]})\n",
    "                        sim.SetStatus([right_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current * best_match_value, 0.0]})\n",
    "\n",
    "                        best_match_value == None\n",
    "\n",
    "                    input_device == None\n",
    "\n",
    "            sim.Prepare()\n",
    "\n",
    "            sim.Run(time_delta)\n",
    "\n",
    "            ring1_exc, ring1_spikes_exc = np.unique(sim.GetStatus(exc_spikes[0])[0]['events']['senders'], return_counts = True)\n",
    "            ring2_exc, ring2_spikes_exc = np.unique(sim.GetStatus(exc_spikes[1])[0]['events']['senders'], return_counts = True)\n",
    "            ring3_exc, ring3_spikes_exc = np.unique(sim.GetStatus(exc_spikes[2])[0]['events']['senders'], return_counts = True)\n",
    "\n",
    "            current_exc_state[0, ring1_exc-min(exc[0])] = ring1_spikes_exc if ring1_spikes_exc.size > 0 else 0\n",
    "            current_exc_state[1, ring2_exc-min(exc[1])] = ring2_spikes_exc if ring2_spikes_exc.size > 0 else 0\n",
    "            current_exc_state[2, ring3_exc-min(exc[2])] = ring3_spikes_exc if ring3_spikes_exc.size > 0 else 0\n",
    "\n",
    "            ring1_most_active_exc_index = np.argmax(current_exc_state[0, :]) if np.argmax(current_exc_state[0, :]) is not None else None\n",
    "            ring2_most_active_exc_index = np.argmax(current_exc_state[1, :]) if np.argmax(current_exc_state[1, :]) is not None else None\n",
    "            ring3_most_active_exc_index = np.argmax(current_exc_state[2, :]) if np.argmax(current_exc_state[2, :]) is not None else None\n",
    "\n",
    "            current_most_active_exc = (ring1_most_active_exc_index, ring2_most_active_exc_index, ring3_most_active_exc_index)\n",
    "\n",
    "            if np.all(None not in current_most_active_exc) and t > start_delay:\n",
    "\n",
    "                exc_state_history[tick, 0, ring1_exc-min(exc[0])] = ring1_spikes_exc\n",
    "                exc_state_history[tick, 1, ring2_exc-min(exc[1])] = ring2_spikes_exc\n",
    "                exc_state_history[tick, 2, ring3_exc-min(exc[2])] = ring3_spikes_exc\n",
    "\n",
    "            ring1_rp, ring1_spikes_rp = np.unique(sim.GetStatus(pa_spikes[0])[0]['events']['senders'], return_counts = True)\n",
    "            ring2_rp, ring2_spikes_rp = np.unique(sim.GetStatus(pa_spikes[1])[0]['events']['senders'], return_counts = True)\n",
    "            ring3_rp, ring3_spikes_rp = np.unique(sim.GetStatus(pa_spikes[2])[0]['events']['senders'], return_counts = True)\n",
    "\n",
    "            current_rp_state[0, ring1_rp-min(pa_cells[0])] = ring1_spikes_rp if ring1_spikes_rp.size > 0 else 0\n",
    "            current_rp_state[1, ring2_rp-min(pa_cells[1])] = ring2_spikes_rp if ring2_spikes_rp.size > 0 else 0\n",
    "            current_rp_state[2, ring3_rp-min(pa_cells[2])] = ring3_spikes_rp if ring3_spikes_rp.size > 0 else 0\n",
    "\n",
    "            ring1_most_active_rp_index = np.argmax(current_rp_state[0, :]) if np.argmax(current_rp_state[0, :]) is not None else None\n",
    "            ring2_most_active_rp_index = np.argmax(current_rp_state[1, :]) if np.argmax(current_rp_state[1, :]) is not None else None\n",
    "            ring3_most_active_rp_index = np.argmax(current_rp_state[2, :]) if np.argmax(current_rp_state[2, :]) is not None else None\n",
    "\n",
    "            current_most_active_rp = (ring1_most_active_rp_index, ring2_most_active_rp_index, ring3_most_active_rp_index)\n",
    "\n",
    "            recalled_ring_state_r1, recalled_ring_state_r2, recalled_ring_state_r3 = -1, -1, -1\n",
    "\n",
    "            sim.Cleanup()\n",
    "\n",
    "            # Reset spike detectors so that per-time-delta spike counts are recorded only\n",
    "\n",
    "            if tick % history_timestep_window == 0:\n",
    "\n",
    "                sim.SetStatus(exc_spikes[0], {'n_events': 0})\n",
    "                sim.SetStatus(exc_spikes[1], {'n_events': 0})\n",
    "                sim.SetStatus(exc_spikes[2], {'n_events': 0})\n",
    "\n",
    "            if corrections == True and np.all(None not in current_most_active_rp) and t == representation_times[representation_index]:\n",
    "\n",
    "                if len(sense_memories) == 0:\n",
    "\n",
    "                    sense_memories.append(representations[representation_index])\n",
    "\n",
    "                if len(location_memories) == 0:\n",
    "\n",
    "                    location_memories.append(current_most_active_rp)\n",
    "                    #location_memories.append((0,0,0))\n",
    "\n",
    "                    memory_state_history.append({\"Timestep\": tick, \"Memory Created\": new_memories, \"Active Ring 1\": current_most_active_rp[0], \n",
    "                                                                        \"Active Ring 2\": current_most_active_rp[1], \"Active Ring 3\": current_most_active_rp[2]})\n",
    "\n",
    "                pearson_coorelation = np.empty(shape = (len(sense_memories)))\n",
    "\n",
    "                for sm, sense_memory in enumerate(sense_memories):\n",
    "\n",
    "                    pearson_coorelation[sm] = pearsonr(representations[representation_index], sense_memory)[0]\n",
    "\n",
    "                best_match_index = np.argmax(pearson_coorelation) if pearson_coorelation.size > 0 else None\n",
    "\n",
    "                best_match_element = sense_memories[best_match_index] if best_match_index is not None else None\n",
    "\n",
    "                best_match_value = pearson_coorelation[best_match_index] if best_match_index is not None else None\n",
    "\n",
    "\n",
    "                if best_match_value is None and timestamp > start_delay:\n",
    "\n",
    "                    no_spike_timeout -= 1\n",
    "\n",
    "\n",
    "                elif best_match_value >= recall_threshold and t > representation_times[0]: # The 2nd condition is to prevent recalls happening immediately for the first (automatically added) memory. Recalls can still happen later to this memory as per usual\n",
    "\n",
    "                    recalls += 1\n",
    "\n",
    "                    recalled_ring_state_r1, recalled_ring_state_r2, recalled_ring_state_r3 = location_memories[best_match_index]\n",
    "\n",
    "                    # recalled_ring_state_r1 += 1\n",
    "                    # recalled_ring_state_r2 += 1\n",
    "                    # recalled_ring_state_r3 += 1\n",
    "\n",
    "    #                     ring1_injection_device = input_device_to_ring_cells_connections[pa_to_pyramidal_connections[\"Ring 1 Index\"] == recalled_ring_state_r1][\"Source Device\"]\n",
    "    #                     ring2_injection_device = input_device_to_ring_cells_connections[pa_to_pyramidal_connections[\"Ring 2 Index\"] == recalled_ring_state_r2][\"Source Device\"]\n",
    "    #                     ring3_injection_device = input_device_to_ring_cells_connections[pa_to_pyramidal_connections[\"Ring 3 Index\"] == recalled_ring_state_r3][\"Source Device\"]\n",
    "\n",
    "                    #try:\n",
    "\n",
    "                    input_device = int(input_device_to_ring_cells_connections.query(\"`Ring 1 Virtual RP` == @recalled_ring_state_r1 and `Ring 2 Virtual RP` == @recalled_ring_state_r2 and `Ring 3 Virtual RP` == @recalled_ring_state_r3\")['Source Device'].values[0])\n",
    "\n",
    "                    #except:\n",
    "\n",
    "                        #print(f\"Query unsuccessful; likely corrective input targets do not exist on ring. Corrective input targets 1,2,3: {recalled_ring_state_r1},{recalled_ring_state_r2},{recalled_ring_state_r3}\")\n",
    "\n",
    "                    #print(f\"Latest exc spike time: {sim.GetStatus(exc_spikes[0])[0]['events']['times'][-1]}\")\n",
    "\n",
    "                    target_exc_cell_r1 = int(input_device_to_ring_cells_connections.query(\"`Ring 1 Virtual RP` == @recalled_ring_state_r1 and `Ring 2 Virtual RP` == @recalled_ring_state_r2 and `Ring 3 Virtual RP` == @recalled_ring_state_r3\")['Ring 1 Index'].values[0])\n",
    "                    target_exc_cell_r2 = int(input_device_to_ring_cells_connections.query(\"`Ring 1 Virtual RP` == @recalled_ring_state_r1 and `Ring 2 Virtual RP` == @recalled_ring_state_r2 and `Ring 3 Virtual RP` == @recalled_ring_state_r3\")['Ring 2 Index'].values[0])\n",
    "                    target_exc_cell_r3 = int(input_device_to_ring_cells_connections.query(\"`Ring 1 Virtual RP` == @recalled_ring_state_r1 and `Ring 2 Virtual RP` == @recalled_ring_state_r2 and `Ring 3 Virtual RP` == @recalled_ring_state_r3\")['Ring 3 Index'].values[0])\n",
    "\n",
    "                    #print(f\"Injecting with device {input_device} targetting RPs: {(recalled_ring_state_r1, recalled_ring_state_r2, recalled_ring_state_r3)} at time {t}, timestep: {tick} until {t+correction_duration}\")\n",
    "\n",
    "                    injection_state_history[tick:tick+int(correction_duration // 20), 0, target_exc_cell_r1] = 1\n",
    "                    injection_state_history[tick:tick+int(correction_duration // 20), 1, target_exc_cell_r2] = 1\n",
    "                    injection_state_history[tick:tick+int(correction_duration // 20), 2, target_exc_cell_r3] = 1\n",
    "\n",
    "                    memory_state_history.append({\"Timestep\": tick, \"Recalled Memory\": best_match_index, \"Recalled Ring 1\": recalled_ring_state_r1, \n",
    "                                                                        \"Recalled Ring 2\": recalled_ring_state_r2, \"Recalled Ring 3\": recalled_ring_state_r3}) \n",
    "\n",
    "                elif best_match_value < recall_threshold:\n",
    "\n",
    "                    new_memories += 1\n",
    "\n",
    "                    sense_memories.append(representations[representation_index])\n",
    "\n",
    "                    location_memories.append(current_most_active_rp)\n",
    "\n",
    "                    memory_state_history.append({\"Timestep\": tick, \"Memory Created\": new_memories, \"Active Ring 1\": current_most_active_rp[0], \n",
    "                                                                        \"Active Ring 2\": current_most_active_rp[1], \"Active Ring 3\": current_most_active_rp[2]}) \n",
    "\n",
    "    #             else:\n",
    "\n",
    "    #                 print(\"Help\")\n",
    "\n",
    "                if no_spike_timeout <= 0:\n",
    "\n",
    "                    print(f\"No spikes have been recorded for {no_spike_timeout} input cycles, stopping...\")\n",
    "\n",
    "                    break\n",
    "\n",
    "                if representation_index < (len(representation_times) - 1):\n",
    "\n",
    "                    representation_index += 1\n",
    "\n",
    "            print(f\"Timestep: {tick+1}/{len(time_deltas)}; Sim Time: {int(t)}; Ring State: {current_most_active_exc}; RP State: {current_most_active_rp}; Injection Sites: {(recalled_ring_state_r1, recalled_ring_state_r2, recalled_ring_state_r3)}; Memories Stored: {new_memories}; Recall events: {recalls}\", end = '\\r')\n",
    "\n",
    "    pd.DataFrame(memory_state_history)\n",
    "\n",
    "    if corrections:\n",
    "\n",
    "        np.save(\"corrected_exc_state_history.npy\", exc_state_history)\n",
    "\n",
    "    elif not corrections:\n",
    "\n",
    "        np.save(\"uncorrected_exc_state_history.npy\", exc_state_history)\n",
    "\n",
    "\n",
    "    circular_mean = True # If False, ring position is taken to be the index of the most active cell\n",
    "\n",
    "    metric_plot = 'distance'\n",
    "\n",
    "    cumulative_or_mean = 'mean'\n",
    "    \n",
    "\n",
    "    cell_indices_for_plotting = (np.linspace(0, 2*np.pi, num = N_ex, endpoint = False) + ((2*np.pi) / N_ex)) % N_ex\n",
    "\n",
    "    most_active_cell_indices = ((np.argmax(exc_state_history, axis = 2) + 1) / N_ex * 2*np.pi) % N_ex\n",
    "    most_active_cell_values = np.max(exc_state_history, axis = 2)\n",
    "\n",
    "    \n",
    "    ring_1_mean_activity_index = ring_mean_activity(exc_state_history[:, 0, :], centre = True)\n",
    "    ring_2_mean_activity_index = ring_mean_activity(exc_state_history[:, 1, :], centre = True)\n",
    "    ring_3_mean_activity_index = ring_mean_activity(exc_state_history[:, 2, :], centre = True)\n",
    "\n",
    "    if circular_mean:\n",
    "\n",
    "        ring_1_unwrapped = np.unwrap(ring_1_mean_activity_index, period = N_ex // (1 * np.pi))\n",
    "        ring_2_unwrapped = np.unwrap(ring_2_mean_activity_index, period = N_ex // (1 * np.pi))\n",
    "        ring_3_unwrapped = np.unwrap(ring_3_mean_activity_index, period = N_ex // (1 * np.pi))\n",
    "\n",
    "    else:\n",
    "\n",
    "        ring_1_unwrapped = np.unwrap(np.argmax(exc_state_history[:, 0, :], axis = 1), period = N_ex // (1 * np.pi))\n",
    "        ring_2_unwrapped = np.unwrap(np.argmax(exc_state_history[:, 1, :], axis = 1), period = N_ex // (1 * np.pi))\n",
    "        ring_3_unwrapped = np.unwrap(np.argmax(exc_state_history[:, 2, :], axis = 1), period = N_ex // (1 * np.pi))\n",
    "\n",
    "    ring_xy = ring2cart(ring_1_unwrapped, ring_2_unwrapped, ring_3_unwrapped, offset = -90)\n",
    "\n",
    "    ring_xy[:, 0] = (ring_xy[:, 0] - min(ring_xy[:, 0])) / (max(ring_xy[:, 0]) - min(ring_xy[:, 0]))\n",
    "    ring_xy[:, 1] = (ring_xy[:, 1] - min(ring_xy[:, 1])) / (max(ring_xy[:, 1]) - min(ring_xy[:, 1]))\n",
    "\n",
    "    ring_xy[:, 0] = ring_xy[:, 0] * (max(pos_x) - min(pos_x)) + min(pos_x)\n",
    "    ring_xy[:, 1] = ring_xy[:, 1] * (max(pos_y) - min(pos_y)) + min(pos_y)\n",
    "\n",
    "\n",
    "    if metric_plot == 'spearman':\n",
    "\n",
    "        ground_truth_vector_magnitude = np.sqrt(pos_x[start_delay:] ** 2 + pos_y[start_delay:] ** 2)\n",
    "        estimated_vector_magnitude = np.sqrt(ring_xy[start_delay:,0] ** 2 + ring_xy[start_delay:,1] ** 2)\n",
    "\n",
    "        spearman_r_over_time = [spearmanr(ground_truth_vector_magnitude[:i+2], estimated_vector_magnitude[:i+2], alternative = 'greater')[0] for i in range(len(pos_x[start_delay:])-1)]\n",
    "        spearman_p_over_time = [spearmanr(ground_truth_vector_magnitude[:i+3], estimated_vector_magnitude[:i+3], alternative = 'greater')[1] for i in range(len(pos_x[start_delay:])-1)]\n",
    "\n",
    "    elif metric_plot == 'error':\n",
    "\n",
    "        pointwise_error_over_time = np.abs(pos_x[:] - ring_xy[:, 0]) + np.abs(pos_y[:] - ring_xy[:, 1])\n",
    "        cumulative_error_over_time = np.cumsum(pointwise_error_over_time)\n",
    "\n",
    "        if cumulative_or_mean == 'mean':\n",
    "\n",
    "            cumulative_error_over_time = cumulative_error_over_time / np.arange(1, len(cumulative_error_over_time) + 1)\n",
    "\n",
    "    elif metric_plot == 'distance':\n",
    "\n",
    "        pointwise_distance_over_time = np.sqrt((pos_x[:] - ring_xy[:, 0]) ** 2 + (pos_y[:] - ring_xy[:, 1]) ** 2)\n",
    "        cumulative_distance_over_time = np.cumsum(pointwise_distance_over_time)\n",
    "\n",
    "        if cumulative_or_mean == 'mean':\n",
    "\n",
    "            cumulative_distance_over_time = cumulative_distance_over_time / np.arange(1, len(cumulative_distance_over_time) + 1)\n",
    "            \n",
    "\n",
    "    if not os.path.exists(\"results_window_size_15.csv\"):\n",
    "\n",
    "        results_dataframe = pd.DataFrame({\"Master Seed\": master_seed, \"Membrane Seed\": membrane_seed, \"Input Seed\": input_seed, \"Input Sigma\": input_current_sigma,\n",
    "                                          \"Corrected\":corrections, \"Minimum Input\": minimum_input, \"Window Size\": window_size, \"RP Offset\": rp_offset,\n",
    "                                          \"Correction Duration\": correction_duration, \"Correction Current\": correction_current, \"Confidence Scaling\": confidence_scaling,\n",
    "                                          \"Recall Threshold\": recall_threshold, \"Memories Stored\": len(sense_memories), \"Recalls\": recalls, \n",
    "                                          \"Mean Error\": cumulative_distance_over_time[-1], \"Final Position Error\": pointwise_distance_over_time[-1]},\n",
    "                                        index = [1])\n",
    "\n",
    "        results_dataframe.to_csv(\"results_window_size_15.csv\", index = False)\n",
    "\n",
    "    else:\n",
    "\n",
    "        results_dataframe = pd.read_csv(\"results_window_size_15.csv\")\n",
    "\n",
    "        new_results = pd.DataFrame({\"Master Seed\": master_seed, \"Membrane Seed\": membrane_seed, \"Input Seed\": input_seed, \"Input Sigma\": input_current_sigma,\n",
    "                                    \"Corrected\":corrections, \"Minimum Input\": minimum_input, \"Window Size\": window_size, \"RP Offset\": rp_offset,\n",
    "                                    \"Correction Duration\": correction_duration, \"Correction Current\": correction_current, \"Confidence Scaling\": confidence_scaling,\n",
    "                                    \"Recall Threshold\": recall_threshold, \"Memories Stored\": len(sense_memories), \"Recalls\": recalls, \n",
    "                                    \"Mean Error\": cumulative_distance_over_time[-1], \"Final Position Error\": pointwise_distance_over_time[-1]},\n",
    "                                    index = [len(results_dataframe) + 1])\n",
    "\n",
    "        results_dataframe = pd.concat([results_dataframe, new_results])\n",
    "\n",
    "        results_dataframe.to_csv(\"results_window_size_15.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5fa93-26cc-4a0a-85cd-56f613abea08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
